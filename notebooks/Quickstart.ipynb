{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This tutorial will make you acquianted with all basic DialogFlow features.\n",
    "\n",
    "<a id='legend'></a>\n",
    "In this tutorial, we will illustrate the DialogFlow functionality using the diagrams. Here is the legend for our diagrams.\n",
    "<img src=\"legend.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "Here are the links on the examples:\n",
    "[Example 1](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_1_basics.py)\n",
    "[Example 2](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_2_conditions.py)\n",
    "[Example 3](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_3_responses.py)\n",
    "[Example 4](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_4_transitions.py)\n",
    "[Example 5](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_5_global_transitions.py)\n",
    "[Example 6](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_6_context_serialization.py)\n",
    "[Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py)\n",
    "[Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py)\n",
    "[Example 9](https://github.com/deepmipt/dialog_flow_engine/blob/dev/example/example_9_pre_transitions_processing.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='actor'></a>\n",
    "\n",
    "The object that executes dialog is `Actor`. After we define `script`, we initialize `Actor` with script, start node, fallback node and default label priority.\n",
    "\n",
    "Start node is the node where the dialog starts. Fallback node is the node where the dialog goes when there are no available transitions. \n",
    "\n",
    "The dialog is defined in `script`. The `script` is a flow dictionary that contains `flows` and the optional `GLOBAL` field with parameters.\n",
    "<img src=\"script.png\" width=\"800\" height=\"600\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='flow'></a>\n",
    "\n",
    "Every `flow` is also a dictionary that has multiple `nodes` and the optional `LOCAL` field with parameters. It can be convenient to denote every topic by separate `flows`. \n",
    "<img src=\"flow.png\" width=\"800\" height=\"600\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='node'></a>\n",
    "\n",
    "`Node` is the basic element of the framework.\n",
    "<img src=\"node.png\" width=\"800\" height=\"600\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='response'></a>\n",
    "\n",
    "`Node` is a dictionary, where the key is the name of node, and value is the dictionary with following keys:\n",
    "\n",
    "\n",
    "* `PRE_RESPONSE_PROCESSING` ( OPTIONAL) contains the dictionary of preprocessings that are applied to the response.\n",
    "\n",
    "* `RESPONSE` contains the response the node outputs. Response can be a string or a function. \n",
    "If `RESPONSE` is a function, it must take `Context` and `Actor` as first and second argument respectively, just like here.\n",
    "<img src=\"response_function.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "\n",
    "Response function can take different arguments, but in this case it must be called with these arguments in script.\n",
    "<img src=\"response_complex_function.png\" width=\"800\" height=\"600\"> Example of such function is  the function [responses.choice](https://github.com/deepmipt/dialog_flow_engine/blob/dev/df_engine/responses.py)\n",
    "\n",
    "\n",
    "You can see examples of working with response functions in [Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_3_responses.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id='response2'></a>\n",
    "\n",
    "\n",
    "Note, that if `RESPONSE` is a function, and in `PRE_RESPONSE_PROCESSING` you modify response string, you must call the function in `PRE_RESPONSE_PROCESSING`,  like here:\n",
    "    \n",
    "<img src=\"pre_response_processing_complex.png\" width=\"800\" height=\"600\"> \n",
    "<img src=\"pre_response_processing_user.png\" width=\"800\" height=\"600\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='transition'></a>\n",
    "\n",
    "* `PRE_TRANSITION_PROCESSING`  ( OPTIONAL) contains the dictionary of preprocessings that are applied to the transition.\n",
    "\n",
    "* `TRANSITIONS` contains the dictionary of transitions from this node to other nodes. In each dictionary, key is the tuple (next_flow, next_node), and value is the condition of transition to this flow and node.\n",
    "\n",
    "Here is how the transitions are being processed.\n",
    "\n",
    "<img src=\"processing_transitions.png\" width=\"800\" height=\"600\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='selecting'></a>\n",
    "\n",
    "If there are no transitions to process, we process in the same way transitions from the upper level - once they appear.\n",
    "\n",
    "<img src=\"selecting_transitions.png\" width=\"800\" height=\"600\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='misc'></a>\n",
    "\n",
    "* `MISC` (OPTIONAL) is a dictionary of values that can be accessed by any other functions.\n",
    "You can see examples of working with `MISC` in [Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dfe_labels'></a>\n",
    "\n",
    "Note that in `TRANSITIONS`, function from dff_engine.labels can also be the keys. You can see what different functions do in this picture.\n",
    "\n",
    "<img src=\"dfe_labels.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "You can find examples of using these functions in [Example 4](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_4_transitions.py), [Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py), [Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py) and [Example 9](https://github.com/deepmipt/dialog_flow_engine/blob/dev/example/example_9_pre_transitions_processing.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dfe_condition'></a>\n",
    "\n",
    "Also, for every transition, the possible conditions supported by the library is shown here.\n",
    "\n",
    "<img src=\"dfe_condition.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "You can also make your own condition function, but it must take `Context` and Actor as first and second argument respectively, just like the response function. Such function can be passed as a value without evaluating.\n",
    "Here is the example of such function.\n",
    "<img src=\"custom_condition.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "You can also pass as a condition function that takes different arguments, but it must return function that takes `Context` and `Actor`.\n",
    "Here is the example of such function.\n",
    "<img src=\"custom_complex_condition.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "\n",
    "You can find examples of working with conditions in [Example 2](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_2_conditions.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='local_global'></a>\n",
    "\n",
    "`LOCAL` and `GLOBAL` have the same structure as `Node`, but without `RESPONSE`.\n",
    "\n",
    "<img src=\"local_global.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "You can see the examples of using `GLOBAL` in [Example 5](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_5_global_transitions.py),[Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py),[Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py) and [Example 9](https://github.com/deepmipt/dialog_flow_engine/blob/dev/example/example_9_pre_transitions_processing.py)\n",
    "Among these examples, `LOCAL` is used in [Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py) and [Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overwrite'></a>\n",
    "\n",
    "\n",
    "Any variable from `PRE_TRANSITION_PROCESSING`,`PRE_RESPONSE_PROCESSING`,`TRANSITIONS` and  `MISC` from every level can be overwritten on the lower level.\n",
    "\n",
    "<img src=\"overwriting_variables.png\" width=\"800\" height=\"600\"> \n",
    "You can see the example of overwriting `TRANSITIONS` in [Example 5](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_5_global_transitions.py), examples of overwriting `PRE_TRANSITION_PROCESSING` values in [Example 7](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_7_pre_response_processing.py), examples of overwriting `MISC` values in [Example 8](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_8_misc.py) and examples of overwriting `PRE_TRANSITION_PROCESSING` in [Example 9](https://github.com/deepmipt/dialog_flow_engine/blob/dev/example/example_9_pre_transitions_processing.py).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='turn_handler'></a>\n",
    "\n",
    "\n",
    "Turn_handler is a function that obtains bot answer for every turn. It adds a next user request, `in_request`, into the `context.` Then `Actor` processes the `context`, in function the response is logged, and the response along with the `context` is returned.\n",
    "\n",
    "Note that  `context` can be serialized to dict or to the json string, as in [Example 6](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_6_context_serialization.py).\n",
    "\n",
    "For the node where the user is, the processing in the turn_handler always goes in the following order.\n",
    "\n",
    "<img src=\"node_execution_order.png\" width=\"800\" height=\"600\"> \n",
    "\n",
    "You can see the simple example of turn_handler in [Example 1](https://github.com/deepmipt/dialog_flow_engine/blob/dev/examples/example_1_basics.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_engine.core.keywords import GLOBAL, TRANSITIONS, RESPONSE, MISC, LOCAL\n",
    "from df_engine.core.keywords import PRE_RESPONSE_PROCESSING, PRE_TRANSITIONS_PROCESSING\n",
    "from df_engine.core import Context, Actor\n",
    "import df_engine.conditions as cnd\n",
    "import df_engine.responses as rsp\n",
    "import df_engine.labels as lbl\n",
    "from examples import example_1_basics\n",
    "from df_engine.core.types import NodeLabel3Type\n",
    "from typing import Union, Optional, Any\n",
    "import logging\n",
    "import re\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here is the example of a chatbot in DialogFlow Framework. We will explain every function and give references to the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the condition function, that checks if user text is castable to string.\n",
    "Complex conditions are explained [here](#dfe_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def request_is_castable(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    request = ctx.last_request\n",
    "    request_is_castable = False\n",
    "    try:  # check if request is castable from str\n",
    "        request = eval(request)\n",
    "        request_is_castable = True\n",
    "    except:\n",
    "        pass\n",
    "    return request_is_castable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the example of transition function, that returns tuple (name of flow, name of node, priority)\n",
    "The role of priority in transition choice is explained [here](#selecting) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_node_ok_transition(ctx: Context, actor: Actor, *args, **kwargs) -> NodeLabel3Type:\n",
    "    return (\"flow\", \"node_ok\", 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_previous_node_response_to_ctx_processing(ctx: Context, actor: Actor, prefix=None, *args, **kwargs) -> Context:\n",
    "    processed_node = ctx.current_node\n",
    "    ctx.misc[\"previous_node_response\"] = processed_node.response\n",
    "    if prefix is not None:\n",
    "        if not callable(ctx.misc[\"previous_node_response\"]):\n",
    "            processed_node.response = f\"{prefix}: {ctx.misc['previous_node_response']}\"\n",
    "        elif callable(processed_node.response):\n",
    "            processed_node.response = f\"{prefix}: {ctx.misc['previous_node_response'](ctx, actor, *args, **kwargs)}\"\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(prefix):\n",
    "    def add_prefix_processing(ctx: Context, actor: Actor, *args, **kwargs) -> Context:\n",
    "        processed_node = ctx.current_node\n",
    "        if not callable(processed_node.response):\n",
    "            processed_node.response = f\"{prefix}: {processed_node.response}\"\n",
    "        elif callable(processed_node.response):\n",
    "            processed_node.response = f\"{prefix}: {processed_node.response(ctx, actor, *args, **kwargs)}\"\n",
    "        ctx.overwrite_current_node_in_processing(processed_node)\n",
    "        return ctx\n",
    "\n",
    "    return add_prefix_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_misc():\n",
    "    def add_misc_processing(ctx: Context, actor: Actor, *args, **kwargs) -> Context:\n",
    "        processed_node = ctx.current_node\n",
    "        if not callable(processed_node.response):\n",
    "            processed_node.response = f\"misc: {processed_node.misc} {processed_node.response}\"\n",
    "        elif callable(processed_node.response):\n",
    "            processed_node.response = (\n",
    "                f\"misc: {processed_node.misc} \" f\"{processed_node.response(ctx, actor, *args, **kwargs)}\"\n",
    "            )\n",
    "        ctx.overwrite_current_node_in_processing(processed_node)\n",
    "        return ctx\n",
    "\n",
    "    return add_misc_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_priority_node_transition(flow_label, label):\n",
    "    def transition(ctx: Context, actor: Actor, *args, **kwargs) -> NodeLabel3Type:\n",
    "        return (flow_label, label, 2.0)\n",
    "\n",
    "    return transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_case_response(response: str):\n",
    "    return response.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def okay_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    return str(rsp.choice([\"OKAY\", \"OK\"])(ctx, actor, *args, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the response function, that logs the context and returns the dictionary with previous node and last request.\n",
    "More information about response functions can be found [here](#response) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fallback_trace_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    logger.warning(f\"ctx={ctx}\")\n",
    "    return str(\n",
    "        {\n",
    "            \"previous_node\": list(ctx.labels.values())[-2],\n",
    "            \"last_request\": ctx.last_request,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_about_topic_response(ctx: Context, actor: Actor, *args, **kwargs) -> Any:\n",
    "    request = ctx.last_request\n",
    "    topic_pattern = re.compile(r\"(.*talk about )(.*)\\.\")\n",
    "    topic = topic_pattern.findall(request)\n",
    "    topic = topic and topic[0] and topic[0][-1]\n",
    "    if topic:\n",
    "        return f\"Sorry, I can not talk about {topic} now. Dialog len {len(ctx.requests)}\"\n",
    "    else:\n",
    "        return f\"Sorry, I can not talk about that now. {len(ctx.requests)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_about_topic_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    request = ctx.last_request\n",
    "    return \"talk about\" in request.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_lower_case_condition(ctx: Context, actor: Actor, *args, **kwargs) -> bool:\n",
    "    request = ctx.last_request\n",
    "    return \"no\" in request.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create script of dialog\n",
    "\n",
    "script = {\n",
    "    GLOBAL: {\n",
    "        TRANSITIONS: {\n",
    "            (\"global_flow\", \"start_node\", 1.5): cnd.exact_match(\"global start\"),\n",
    "            (\"flow\", \"node_hi\", 1.5): cnd.exact_match(\"global hi\"),\n",
    "        },\n",
    "        MISC: {\"var1\": \"global_data\", \"var2\": \"global_data\", \"var3\": \"global_data\"},\n",
    "        PRE_RESPONSE_PROCESSING: {\n",
    "            \"proc_name_1\": add_prefix(\"l1_global\"),\n",
    "            \"proc_name_2\": add_prefix(\"l2_global\"),\n",
    "        },\n",
    "        PRE_TRANSITIONS_PROCESSING: {\"proc_tr__name_1\": save_previous_node_response_to_ctx_processing},\n",
    "    },\n",
    "    \"global_flow\": {\n",
    "        \"start_node\": {\n",
    "            RESPONSE: \"INITIAL NODE\",\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_hi\"): cnd.regexp(r\"base\"),\n",
    "                \"fallback_node\": cnd.true(),\n",
    "            },\n",
    "        },\n",
    "        \"fallback_node\": {\n",
    "            RESPONSE: \"oops\",\n",
    "            TRANSITIONS: {\n",
    "                lbl.previous(): cnd.exact_match(\"initial\"),\n",
    "                # to global flow start node\n",
    "                lbl.repeat(): cnd.true()\n",
    "                # global flow, fallback node\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"flow\": {\n",
    "        LOCAL: {\n",
    "            MISC: {\n",
    "                \"var2\": \"rewrite_by_flow\",\n",
    "                \"var3\": \"rewrite_by_flow\",\n",
    "            },\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow\"),\n",
    "                \"proc_name_2\": add_prefix(\"l2_flow\"),\n",
    "            },\n",
    "            PRE_TRANSITIONS_PROCESSING: {\"proc_tr__name_2\": save_previous_node_response_to_ctx_processing},\n",
    "        },\n",
    "        \"node_hi\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_hi\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_hi\"),\n",
    "                \"proc_name_2\": add_prefix(\"l2_flow_hi\"),\n",
    "                \"proc_name_3\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: \"Hi!!!\",\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                (\"flow\", \"node_hi\"): cnd.exact_match(\"Hi\"),\n",
    "                high_priority_node_transition(\"flow\", \"node_no\"): no_lower_case_condition,\n",
    "                (\"flow\", \"node_topic\"): talk_about_topic_condition,\n",
    "                flow_node_ok_transition: cnd.all([cnd.true(), cnd.has_last_labels(flow_labels=[\"global_flow\"])]),\n",
    "            },\n",
    "        },\n",
    "        \"node_no\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_NO\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_no\"),\n",
    "                \"proc_name_2\": add_prefix(\"l2_flow_no\"),\n",
    "                \"proc_name_3\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: upper_case_response(\"NO\"),\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                (\"flow\", \"node_hi\"): cnd.regexp(r\"hi\"),\n",
    "                (\"flow\", \"node_topic\"): talk_about_topic_condition,\n",
    "                lbl.to_fallback(0.1): cnd.true(),\n",
    "            },\n",
    "        },\n",
    "        \"node_complex\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_COMPLEX\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_complex\"),\n",
    "                \"proc_name_2\": add_prefix(\"l2_flow_complex\"),\n",
    "                \"proc_name_3\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: \"Not string detected\",\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                (\"flow\", \"node_hi\"): cnd.regexp(r\"hi\"),\n",
    "                lbl.to_fallback(0.1): cnd.true(),\n",
    "            },\n",
    "        },\n",
    "        \"node_topic\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_TOPIC\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_topic\"),\n",
    "                \"proc_name_2\": add_prefix(\"l2_flow_topic\"),\n",
    "                \"proc_name_3\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: talk_about_topic_response,\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                lbl.forward(0.5): cnd.any([cnd.regexp(r\"ok\"), cnd.regexp(r\"o k\")]),\n",
    "                lbl.backward(0.5): cnd.any([cnd.regexp(r\"node complex\"), complex_user_answer_condition]),\n",
    "            },\n",
    "        },\n",
    "        \"node_ok\": {\n",
    "            MISC: {\"var3\": \"rewrite_by_OK\"},\n",
    "            PRE_RESPONSE_PROCESSING: {\n",
    "                \"proc_name_1\": add_prefix(\"l1_flow_ok\"),\n",
    "                \"proc_name_2\": add_prefix(\"l2_flow_ok\"),\n",
    "                \"proc_name_3\": add_misc(),\n",
    "            },\n",
    "            RESPONSE: okay_response,\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                lbl.previous(): cnd.regexp(r\"previous\"),\n",
    "            },\n",
    "        },\n",
    "        \"fallback_node\": {  # We get to this node if an error occurred while the agent was running\n",
    "            RESPONSE: fallback_trace_response,\n",
    "            TRANSITIONS: {\n",
    "                (\"flow\", \"node_complex\"): complex_user_answer_condition,\n",
    "                \"node_hi\": cnd.all([cnd.exact_match(\"Hi\"), cnd.exact_match(\"Hello\")]),\n",
    "                \"node_ok\": cnd.exact_match(\"Okey\"),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init actor\n",
    "actor = Actor(\n",
    "    script,\n",
    "    start_label=(\"global_flow\", \"start_node\"),\n",
    "    fallback_label=(\"global_flow\", \"fallback_node\"),\n",
    "    label_priority=1.0,\n",
    ")\n",
    "\n",
    "\n",
    "# handler requests\n",
    "\n",
    "# turn_handler - a function is made for the convenience of working with an actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_handler(\n",
    "    in_request: str,\n",
    "    ctx: Union[Context, str, dict],\n",
    "    actor: Actor,\n",
    "    true_out_response: Optional[str] = None,\n",
    "):\n",
    "    # Context.cast - gets an object type of [Context, str, dict] returns an object type of Context\n",
    "    ctx = Context.cast(ctx)\n",
    "    # Add in current context a next request of user\n",
    "    ctx.add_request(in_request)\n",
    "    # pass the context into actor and it returns updated context with actor response\n",
    "    ctx = actor(ctx)\n",
    "    #  breakpoint()\n",
    "    # get last actor response from the context\n",
    "    out_response = ctx.last_response\n",
    "    # the next condition branching needs for testing\n",
    "    if true_out_response is not None and true_out_response != out_response:\n",
    "        print(\"request\")\n",
    "        print(in_request)\n",
    "        print(\"response was\")\n",
    "        print(out_response)\n",
    "        print(\"response must be\")\n",
    "        print(true_out_response)\n",
    "        msg = f\"in_request={in_request} -> true_out_response != out_response: {true_out_response} != {out_response}\"\n",
    "        raise Exception(msg)\n",
    "    else:\n",
    "        print(f\"in_request={in_request} -> NODE {list(ctx.labels.values())[-1]} RESPONSE {out_response}\")\n",
    "    return out_response, ctx\n",
    "\n",
    "\n",
    "# edit this dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dialog = [\n",
    "    (\n",
    "        \"base\",\n",
    "        \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_hi'} l2_flow_hi: l1_flow_hi: Hi!!!\",\n",
    "    ),\n",
    "    # start_node -> node1\n",
    "    (\n",
    "        \"no\",\n",
    "        \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_NO'} l2_flow_no: l1_flow_no: NO\",\n",
    "    ),\n",
    "    # node1 -> node2\n",
    "    (\n",
    "        \"talk about books\",\n",
    "        \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_TOPIC'} l2_flow_topic: l1_flow_topic: Sorry, I can not talk about that now. 3\",\n",
    "    ),\n",
    "    # node3 -> node4\n",
    "    (\n",
    "        \"ok\",\n",
    "        \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_OK'} l2_flow_ok: l1_flow_ok: OK\",\n",
    "    ),\n",
    "    # node4 -> node1\n",
    "    (\n",
    "        \"previous\",\n",
    "        \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_TOPIC'} l2_flow_topic: l1_flow_topic: Sorry, I can not talk about that now. 5\",\n",
    "    ),\n",
    "    # node1 -> fallback_node\n",
    "    (\n",
    "        \"{1:2}\",\n",
    "        \"misc: {'var1': 'global_data', 'var2': 'rewrite_by_flow', 'var3': 'rewrite_by_COMPLEX'} l2_flow_complex: l1_flow_complex: Not string detected\",\n",
    "    ),\n",
    "    # fallback_node -> fallback_node\n",
    "    (\n",
    "        \"f\",\n",
    "        \"l2_global: l1_global: oops\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(mode=None):\n",
    "    ctx = {}\n",
    "    for in_request, true_out_response in testing_dialog:\n",
    "        _, ctx = turn_handler(in_request, ctx, actor, true_out_response=true_out_response)\n",
    "        if mode == \"json\":\n",
    "            ctx = ctx.json()\n",
    "            if isinstance(ctx, str):\n",
    "                logging.info(\"context serialized to json str\")\n",
    "            else:\n",
    "                raise Exception(f\"ctx={ctx} has to be serialized to json string\")\n",
    "        elif mode == \"dict\":\n",
    "            ctx = ctx.dict()\n",
    "            if isinstance(ctx, dict):\n",
    "                logging.info(\"context serialized to dict\")\n",
    "            else:\n",
    "                raise Exception(f\"ctx={ctx} has to be serialized to dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive mode\n",
    "def run_interactive_mode(actor):\n",
    "    ctx = {}\n",
    "    while True:\n",
    "        in_request = input(\"type your answer: \")\n",
    "        _, ctx = turn_handler(in_request, ctx, actor)\n",
    "\n",
    "                                          \n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s-%(name)15s:%(lineno)3s:%(funcName)20s():%(levelname)s - %(message)s\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "    # run_test()\n",
    "    run_interactive_mode(actor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
